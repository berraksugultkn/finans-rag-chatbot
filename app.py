
import os
import pandas as pd
import numpy as np
import streamlit as st
from sklearn.neighbors import NearestNeighbors
from sentence_transformers import SentenceTransformer
from typing import List, Tuple

# ============ Ayarlar ============
DATA_PATH = os.getenv("DATA_PATH", "finans_sorulari.csv")
EMB_MODEL = os.getenv("EMB_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
DEFAULT_TOP_K = int(os.getenv("TOP_K", "3"))

# ============ YardÄ±mcÄ± Fonksiyonlar ============
@st.cache_data(show_spinner=False)
def load_csv(path: str) -> pd.DataFrame:
    df = pd.read_csv(path, sep=";")
    df.columns = [c.strip().lower() for c in df.columns]
    return df

@st.cache_resource(show_spinner=False)
def load_encoder(name: str):
    return SentenceTransformer(name)

@st.cache_resource(show_spinner=True)
def build_index(texts: List[str], model_name: str, top_k: int):
    model = load_encoder(model_name)
    embs = model.encode(texts, convert_to_numpy=True, normalize_embeddings=True, show_progress_bar=True)
    nbrs = NearestNeighbors(n_neighbors=min(top_k, len(texts)), metric="cosine")
    nbrs.fit(embs)
    return model, embs, nbrs

def retrieve(query: str, model, embs, nbrs, df: pd.DataFrame, top_k: int) -> pd.DataFrame:
    q = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)
    distances, indices = nbrs.kneighbors(q, n_neighbors=min(top_k, len(df)))
    hits = df.iloc[indices[0]].copy()
    hits["score"] = 1 - distances[0]  # cosine similarity
    return hits

def generate_answer(query: str, contexts: List[Tuple[str, str, str]]) -> str:
    """
    GOOGLE_API_KEY varsa: baÄŸlamÄ± Gemini modeline verip yanÄ±t Ã¼retir.
    Yoksa: en iyi eÅŸleÅŸmenin 'cevap' kolonunu dÃ¶ndÃ¼rÃ¼r.
    """
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        return contexts[0][1]  # AnahtarsÄ±z modda direkt cevabÄ± dÃ¶ndÃ¼r
    
    try:
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("models/gemini-1.5-flash")

        context_text = "\n\n".join([f"Soru: {c[0]}\nCevap: {c[1]}" for c in contexts])
        prompt = (
            "Sen bir finans asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki bilgi tabanÄ±na dayanarak "
            "kullanÄ±cÄ± sorusunu TÃ¼rkÃ§e, kÄ±sa ve net yanÄ±tla.\n\n"
            f"Bilgi:\n{context_text}\n\n"
            f"KullanÄ±cÄ± sorusu: {query}\n\nYanÄ±t:"
        )

        response = model.generate_content(prompt)
        return response.text.strip()

    except Exception as e:
        return f"Gemini Ã§aÄŸrÄ±sÄ±nda hata: {e}"


# ============ UI ============
st.set_page_config(page_title="Finans RAG Chatbot", page_icon="ğŸ’¬", layout="centered")
st.title("ğŸ’¬ Finans RAG Chatbot")
st.caption("Kendi CSV verinle Ã§alÄ±ÅŸan RAG demo (TÃ¼rkÃ§e).")

with st.sidebar:
    st.header("Ayarlar")
    st.write("â€¢ OPENAI_API_KEY girersen LLM ile yanÄ±t Ã¼retir, yoksa en yakÄ±n cevabÄ± getirir.")
    st.write("â€¢ 'kategori' filtresi sadece eÅŸleÅŸen kayÄ±tlarda Ã¶ncelik verir (opsiyonel).")
    st.divider()
    openai_key = st.text_input("OPENAI_API_KEY", type="password", help="Ä°stersen burada gir, ya da ortam deÄŸiÅŸkeni olarak ayarla.")
    if openai_key:
     os.environ["OPENAI_API_KEY"] = openai_key
google_key = st.text_input("GOOGLE_API_KEY", type="password", help="AIzaSyCmE6018lhVwz32_iyr3bfnAhfsH0j9NLg")
if google_key:
    os.environ["GOOGLE_API_KEY"] = google_key

    topk = st.slider("Top-K (baÄŸlam sayÄ±sÄ±)", 1, 10, DEFAULT_TOP_K)
    os.environ["TOP_K"] = str(topk)

# Veri yÃ¼kle
df = load_csv(DATA_PATH)
all_cats = sorted([str(x) for x in df["kategori"].dropna().unique()]) if "kategori" in df.columns else []

st.success(f"Veri yÃ¼klendi: {len(df)} satÄ±r â€¢ Kolonlar: {list(df.columns)}")

# Embed index
topk = DEFAULT_TOP_K
st.write("ğŸ”§ Embed indeks oluÅŸturuluyor... (ilk Ã§alÄ±ÅŸtÄ±rmada model indirilebilir)")
model, embs, nbrs = build_index(df["soru"].astype(str).tolist(), EMB_MODEL, topk)
st.write("âœ… HazÄ±r!")

# Soru-cevap alanÄ±
user_q = st.text_input("Sorunuzu yazÄ±n:", placeholder="Ã–rn: 'BileÅŸik faiz nasÄ±l hesaplanÄ±r?'")
use_cat = st.multiselect("Kategori (opsiyonel):", options=all_cats)
ask = st.button("Sor")

if ask and user_q.strip():
    with st.spinner("AranÄ±yor..."):
        hits = retrieve(user_q, model, embs, nbrs, df, topk)
        if use_cat:
            mask = hits["kategori"].astype(str).isin(use_cat)
            hits = pd.concat([hits[mask], hits[~mask]]).drop_duplicates()
        ctx = list(zip(
            hits["soru"].astype(str).tolist(),
            hits["cevap"].astype(str).tolist(),
            (hits["kategori"].astype(str).tolist() if "kategori" in hits.columns else ["-"]*len(hits))
        ))[:topk]
        answer = generate_answer(user_q, ctx)

    st.subheader("YanÄ±t")
    st.write(answer)

    with st.expander("GÃ¶sterilen baÄŸlam (Top-K):"):
        for i, (soru, cevap, kat) in enumerate(ctx, 1):
            st.markdown(f"**{i}. Skor:** {hits.iloc[i-1]['score']:.3f}")
            st.markdown(f"**Kategori:** {kat}")
            st.markdown(f"**Soru:** {soru}")
            st.markdown(f"**Cevap:** {cevap}")
            st.markdown("---")

st.divider()
st.caption("â“˜ Demo amaÃ§lÄ±dÄ±r. YanÄ±tlar veri setinizle sÄ±nÄ±rlÄ±dÄ±r.")
